{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage,ToolMessage,AIMessageChunk\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import Runnable,RunnableLambda,RunnableSequence,RunnablePassthrough,RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Access them\n",
    "endpoint = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "open_ai_api_key=os.getenv(\"open_ai_api_key\")\n",
    "# print(\"LangChain Endpoint:\", endpoint)\n",
    "# print(\"API Key:\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model_name=\"gpt-4-turbo\",\n",
    "    api_key=open_ai_api_key,\n",
    "    max_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\n",
    "\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "    (\"human\",\"Tell me {joke_count} jokes\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_prompt=RunnableLambda(lambda x: prompt_template.format_prompt(**x))\n",
    "inovke_model=RunnableLambda(lambda x: model.invoke(x.to_messages()))\n",
    "parse_output=RunnableLambda(lambda x:x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=RunnableSequence(first=format_prompt,middle=[inovke_model],last=parse_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"topic\":\"Engineers\",\"joke_count\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are three engineering-themed jokes for you:\n",
      "\n",
      "1. Why did the software engineer go broke? Because he used up all his cache!\n",
      "\n",
      "2. Why was the mechanical engineer found at the beach? He wanted to avoid differential pressure and experience some\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
